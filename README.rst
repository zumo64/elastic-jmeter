JMETER  Elasticsearch Tests 
---------------------------------------

Performs ingestion, query , scroll queries at specified throughput and logs latencies on a CSV file 


Pre-requisites
-------------------

Install Jmeter 3.0
Have a ES running cluster accessible

If planning to use the setup.bash script you need :
1.  npm
2.  coffeescript (see http://coffeescript.org/)


If planning to perform scan and scroll queries from Jmeter :
3. you need python 


Setup data and queries 
-------------------------------
* the ./input folder contains bulk indexing JSON files that can be generated by running the setup.bash (as a demo) That's where you need to put your bulk requests files that will be used by JMeter.
* If you want jmeter to send queries, there should be a query input csv (see format below) in ./queries
* If you want jmeter to sens scroll queries, there should be a scroll input csv (see format below) in ./queries



setup.bash
---------------
Use setup.bash script to setup test data from the sample apache logs located in ./ingest/logs.json.gz
This script will generate in ./input 20 BULK requests with 500 docs in each request.
Tweak the parameters in the script to create more bulks / more docs per bulk



cleanup.bash
------------------
This script cleans up all files generated by the tests including results.csv


test.bash
------------
Run this script to perfome  the JMETER test

Modify the test parameters in the script as follows :

JMETER_PATH : The path of your JMeter install
USER= Shield User
PASS= Shield Pass
HOST= Target Elastic hostname/ IP address
PORT= Target Elastic port (ex : 9200)
INDEX= Indices being queried (ex: apachelogs-* )
QUERY_CSV= the file containing queries input in relative to the csv folder  (ex:input1K1h.csv)
SCROLL_CSV=the file containing scroll input   relative to the csv folder (ex:inputScroll.csv) 

QUERY_THROUGHPUT= desired query throughput per minute (ex:5.0)
INDEX_THROUGHPUT=2.0
SCROLL_THROUGHPUT=20.0

elk_stress.jmx runs in the background and takes as additional params :
  -JtestScroll=true/false   : wether we enable the scroll queries to run during the test
  -JtestIngest=true/false   :  ""  ""     ""       ingestion "" "" 
  -JtestQuery=true/false    :   ""  ""    ""        querying 


* if ingestion enabled :
JMeter will iterate the files in ./input and send the bulk queries at specified throughput

* if scroll enabled :
JMeter will iterate the scroll CSV  and send scroll queries at specified throughput  

* if query enabled :
JMeter will iterate the scroll CSV  and send queries  at specified throughput  

 if shield not useed then you have to disable the authentication managers in the Jmeter test plan (using a client).  not tested  with an authentication manager without shield


* Format of the query input CSV :
elk_stress.jmx comes with a generic ES query sampler. This query sampler takes as an input a line in the QUERY_CSV file and inserts each value  in the corresponding query. json body

example (3 lines):

time1,time2,country_code,queryFileName
440772151510,1440775751510,,query1.json
1441972718913,1441976318913,,query1.json
,,US,query2.json


Note the variables time1, time2 referenced in the corresponding query1.json and country_code in query2.json

You can refer to multiple queries in the CSV.. Make sure the CSV headers properly match each CSV values on each rows , ex:

Each query will be sent iteratively by JMeter, and the global throughput will be  QUERY_THROUGHPUT
 
* genDateIntervals.coffee can be used to generate random timestamp intervals.

  
Test results
---------------
Are located in results/results.csv
the latency in ms is the csv file


  
  

  
  
  



